{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercari Price Suggestion Challenge Data Preparation\n",
    "\n",
    "This notebook is for initial preprocessing of data and creating custom sub datasets and train/test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:16:27.464173Z",
     "start_time": "2018-07-21T11:16:27.054084Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:16:33.761358Z",
     "start_time": "2018-07-21T11:16:27.465752Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.column_data import *\n",
    "from fastai.structured import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:16:33.787635Z",
     "start_time": "2018-07-21T11:16:33.763449Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data/')\n",
    "\n",
    "TMP_PATH = DATA_PATH/'intermediate'\n",
    "TMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:16:33.810833Z",
     "start_time": "2018-07-21T11:16:33.789189Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_df(df, test_mask):\n",
    "    df_train, df_test = df[~test_mask], df[test_mask]\n",
    "    df_train.reset_index(inplace=True, drop=True)\n",
    "    df_test.reset_index(inplace=True, drop=True)\n",
    "    return df_train, df_test\n",
    "\n",
    "# na category names are just replaced with 'missing'\n",
    "def split_cat(text):\n",
    "    try:\n",
    "        return text.split('/')\n",
    "    except AttributeError:\n",
    "        return tuple(['missing'] * 3)\n",
    "\n",
    "# replace na or no description values with 'missing'\n",
    "def fix_desc(text):\n",
    "    return 'missing' if not isinstance(text, str) or text == 'No description yet' else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Men', 'Coats & Jackets', 'Flight', 'Bomber']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_cat('Men/Coats & Jackets/Flight/Bomber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('missing', 'missing', 'missing')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(['missing'] * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixup Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:16:50.196956Z",
     "start_time": "2018-07-21T11:16:33.812158Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH/'train.tsv', sep='\\t')\n",
    "test = pd.read_csv(DATA_PATH/'test.tsv', sep='\\t')\n",
    "test2 = pd.read_csv(DATA_PATH/'test_stg2.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are up to four categories that can be seperated from this string but I decided only to consider the first three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.category_name.str.count('/').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sports & Outdoors/Exercise/Dance/Ballet', 'Sports & Outdoors/Outdoors/Indoor/Outdoor Games',\n",
       "       'Men/Coats & Jackets/Varsity/Baseball', 'Men/Coats & Jackets/Flight/Bomber',\n",
       "       'Handmade/Housewares/Entertaining/Serving'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.category_name.str.count('/') == 3].category_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove prices below `$3` as Merari does not allow postings below `$3` which makes it an error. There are `874` entries like that. Mercari also does not allow prices above `$2,000` but there are only 3 entries like that with only a few dollars more which are likely shipping fees. So removing them is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:10.384486Z",
     "start_time": "2018-07-21T11:17:10.066103Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.drop(train[train['price'] < 3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...  \n",
       "4         0          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract subcategories from the main `category_name` and remove it after as we don't need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:10.064371Z",
     "start_time": "2018-07-21T11:16:50.199188Z"
    }
   },
   "outputs": [],
   "source": [
    "train['main_cat'], train['sub_cat1'], train['sub_cat2'] = zip(*train['category_name'].apply(split_cat))                                                              \n",
    "test['main_cat'], test['sub_cat1'], test['sub_cat2'] = zip(*test['category_name'].apply(split_cat))\n",
    "test2['main_cat'], test2['sub_cat1'], test2['sub_cat2'] = zip(*test2['category_name'].apply(split_cat))\n",
    "\n",
    "train.drop('category_name', inplace=True, axis=1)\n",
    "test.drop('category_name', inplace=True, axis=1)\n",
    "test2.drop('category_name', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `na` values in `brand_name` column with `missing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:10.608040Z",
     "start_time": "2018-07-21T11:17:10.386118Z"
    }
   },
   "outputs": [],
   "source": [
    "train['brand_name'].fillna(value='missing', inplace=True)\n",
    "test['brand_name'].fillna(value='missing', inplace=True)\n",
    "test2['brand_name'].fillna(value='missing', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `name` column has nothing missing, but this is added just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:10.608040Z",
     "start_time": "2018-07-21T11:17:10.386118Z"
    }
   },
   "outputs": [],
   "source": [
    "train['name'].fillna(value='missing', inplace=True)\n",
    "test['name'].fillna(value='missing', inplace=True)\n",
    "test2['name'].fillna(value='missing', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `item_condition_id` and `shipping` column to `str` for easy conversion using FastAI's `proc_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:17.010113Z",
     "start_time": "2018-07-21T11:17:10.609560Z"
    }
   },
   "outputs": [],
   "source": [
    "train['shipping'] = train['shipping'].astype('str')\n",
    "test['shipping'] = test['shipping'].astype('str')\n",
    "test2['shipping'] = test2['shipping'].astype('str')\n",
    "\n",
    "train['item_condition_id'] = train['item_condition_id'].astype('str')\n",
    "test['item_condition_id'] = test['item_condition_id'].astype('str')\n",
    "test2['item_condition_id'] = test2['item_condition_id'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `na` values and `No description yet` values in `item_description` with `missing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['item_description'] = train['item_description'].apply(fix_desc)\n",
    "test['item_description'] = test['item_description'].apply(fix_desc)\n",
    "test2['item_description'] = test2['item_description'].apply(fix_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine `name` and `item_description` into one field where the name and description are separated by a newline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_desc'] = train['name'].str.cat(train['item_description'], sep='\\n')\n",
    "test['full_desc'] = test['name'].str.cat(test['item_description'], sep='\\n')\n",
    "test2['full_desc'] = test2['name'].str.cat(test2['item_description'], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop these two columns since they are no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('name', axis=1, inplace=True)\n",
    "train.drop('item_description', axis=1, inplace=True)\n",
    "\n",
    "test.drop('name', axis=1, inplace=True)\n",
    "test.drop('item_description', axis=1, inplace=True)\n",
    "\n",
    "test2.drop('name', axis=1, inplace=True)\n",
    "test2.drop('item_description', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace training sets `price` column with its `np.log1p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:17.065819Z",
     "start_time": "2018-07-21T11:17:17.011683Z"
    }
   },
   "outputs": [],
   "source": [
    "train['price'] = np.log1p(train['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done so that the values for index and `train_id` are not the same and that index reflects the true length of the dataframe such that the last index is of the value `len(df)-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:17.093651Z",
     "start_time": "2018-07-21T11:17:17.067080Z"
    }
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:17.122754Z",
     "start_time": "2018-07-21T11:17:17.094897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['train_id', 'item_condition_id', 'brand_name', 'price', 'shipping',\n",
       "       'main_cat', 'sub_cat1', 'sub_cat2', 'full_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cute Little Devil Minifigure\n",
      "Series 16 - 71013 No. 4 in the Series Cute Little Devil Brand New - Willing to Bundle With Any Items\n"
     ]
    }
   ],
   "source": [
    "print(train['full_desc'][np.random.randint(0, len(train))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created 2 datasets one corresponding to structured data and another unstructured data.\n",
    "1. `struct` contains all columns except `full_desc`\n",
    "2. `unstruct` contains only `full_desc`\n",
    "\n",
    "Both these datasets contain `train_id` and `price`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and create the sub-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:17.147467Z",
     "start_time": "2018-07-21T11:17:17.124060Z"
    }
   },
   "outputs": [],
   "source": [
    "dep = ['price']\n",
    "rid = ['train_id']\n",
    "struct_vars = ['item_condition_id', 'brand_name', 'shipping', 'main_cat', 'sub_cat1', 'sub_cat2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4808\n",
      "2\n",
      "11\n",
      "114\n",
      "871\n"
     ]
    }
   ],
   "source": [
    "for s in struct_vars: print (len(train[s].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:18.243964Z",
     "start_time": "2018-07-21T11:17:17.148669Z"
    }
   },
   "outputs": [],
   "source": [
    "price = train[dep].as_matrix().flatten()\n",
    "train = train[rid + struct_vars + dep ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3979 , 3.97029, 2.3979 , ..., 2.56495, 3.82864, 3.13549])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to have a 10% data for test and 90% for train (and validation). The datasets are created as follows:\n",
    "1. Get a random test mask of length 10% of the total training data\n",
    "2. Extract the dependent variables for train and test using the mask\n",
    "3. Extract train and test for each of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:18.445415Z",
     "start_time": "2018-07-21T11:17:18.245530Z"
    }
   },
   "outputs": [],
   "source": [
    "test_mask = train.index.isin(get_cv_idxs(n = len(train), val_pct=0.1))\n",
    "y_test = price[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:18.908921Z",
     "start_time": "2018-07-21T11:17:18.446968Z"
    }
   },
   "outputs": [],
   "source": [
    "my_train, my_test = split_df(train, test_mask)\n",
    "my_test.drop('price', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for errors\n",
    "\n",
    "Get a random `train_id` and check if the row corresponding to that train id is the same on all dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:20.122927Z",
     "start_time": "2018-07-21T11:17:20.096644Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ae42b97a3b94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "r = np.random.choice(unstruct_train[rid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:20.163108Z",
     "start_time": "2018-07-21T11:17:20.124231Z"
    }
   },
   "outputs": [],
   "source": [
    "struct_train.loc[struct_train[rid] == r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:20.194098Z",
     "start_time": "2018-07-21T11:17:20.164218Z"
    }
   },
   "outputs": [],
   "source": [
    "unstruct_train.loc[unstruct_train[rid] == r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:20.301159Z",
     "start_time": "2018-07-21T11:17:20.265098Z"
    }
   },
   "outputs": [],
   "source": [
    "my_train.loc[my_train[rid] == r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:20.335441Z",
     "start_time": "2018-07-21T11:17:20.302353Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.loc[train[rid] == r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write each custom sub dataset to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:48.522992Z",
     "start_time": "2018-07-21T11:17:20.336589Z"
    }
   },
   "outputs": [],
   "source": [
    "struct_train.to_feather(TMP_PATH/'struct_train.fth')\n",
    "struct_test.to_feather(TMP_PATH/'struct_test.fth')\n",
    "unstruct_train.to_feather(TMP_PATH/'unstruct_train.fth')\n",
    "unstruct_test.to_feather(TMP_PATH/'unstruct_test.df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-20T19:18:18.523570Z",
     "start_time": "2018-07-20T19:18:18.519856Z"
    }
   },
   "source": [
    "Write the dependent variable to disk for both test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:17:48.770079Z",
     "start_time": "2018-07-21T11:17:48.525127Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(TMP_PATH/'y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write my full train and test set which is used during both structured and unstructured data combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:18:01.174095Z",
     "start_time": "2018-07-21T11:17:48.771562Z"
    }
   },
   "outputs": [],
   "source": [
    "my_train.to_feather(TMP_PATH/'my_train.fth')\n",
    "my_test.to_feather(TMP_PATH/'my_test.fth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally write the entire original processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T11:18:49.010642Z",
     "start_time": "2018-07-21T11:18:01.176400Z"
    }
   },
   "outputs": [],
   "source": [
    "train.to_feather(TMP_PATH/'train.fth')\n",
    "test.to_feather(TMP_PATH/'test.fth')\n",
    "test2.to_feather(TMP_PATH/'test2.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
